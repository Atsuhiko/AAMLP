# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UJCami_vv02TNEVaf-70JFf54s7XsAzP
"""

import os
import sys
import torch
import numpy as np
import pandas as pd

!pip install segmentation_models_pytorch

!pip3 install apex

import torch.nn as nn
import torch.optim as optim
# from apex import amp
from collections import OrderedDict
from sklearn import model_selection
from tqdm import tqdm
from torch.optim import lr_scheduler
# from dataset import SIIMDataset
import segmentation_models_pytorch as smp

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/NVIDIA/apex
!pwd
!ls
# %cd ./apex
!pwd
!ls
!pip install -v --disable-pip-version-check --no-cache-dir --global-option="--cpp_ext" --global-option="--cuda_ext" .
#from apex import amp

from apex import amp

from google.colab import drive
drive.mount('/content/drive')

# google drive上のpythonファイルをモジュールとして使用。
# srcフォルダに各種モジュールが入っている
import sys
sys.path.append('/content/drive/MyDrive/Colab_Notebooks/AAMPL/image_classification/Segmentation/src')

from dataset import SIIMDataset

# training csv file path
TRAINING_CSV = "/content/drive/MyDrive/Colab_Notebooks/AAMPL/image_classification/Segmentation/input/train_target_le_norm_2.csv"

# training and test batch sizes
TRAINING_BATCH_SIZE = 16
TEST_BATCH_SIZE = 4
# number of epochs
EPOCHS = 10
# define the encoder for U-Net
# check: https://github.com/qubvel/segmentation_models.pytorch # for all supported encoders
ENCODER = "resnet18"
# we use imagenet pretrained weights for the encoder
ENCODER_WEIGHTS = "imagenet"
# train on gpu
DEVICE = "cuda"

def train(dataset, data_loader, model, criterion, optimizer):
  """
  training function that trains for one epoch
  : param dataset: dataset class (SIIMDataset)
  :param data_loader: torch dataset loader :param model: model
  :param criterion: loss function
  :param optimizer: adam, sgd, etc.
  """
  # put the model in train mode
  model.train()

  # calculate number of batches
  num_batches = int(len(dataset) / data_loader.batch_size)

  # init tqdm to track progress
  tk0 = tqdm(data_loader, total=num_batches)

  # loop over all batches
  for d in tk0:
    #fetch input images and masks from dataset batch
    inputs = d["image"]
    targets = d["mask"]

    # move images and masks to cpu/gpu deivce
    inputs = inputs.to(DEVICE, dtype=torch.flaot)
    targets = targets.to(DEVICE, dtype=torch.float)

    # zero grad the optimizer
    optimizer.zero_grad()

    # forward step of model
    outputs = model(inputs)

    # calculate loss
    loss = criterion(outputs, targets)

    # backward loss is calculates on a scaled loss context since we are using mixed precision training 
    # context since we are using mixed precision training # if you are not using mixed precision training,
    # you can use loss.backward() and delete the following # two lines of code
    with amp.scale_loss(loss, optimizer) as scaled_loss:
      scales_loss.backward()

    # step the optimizer
    optimizer.step()
  
  # close tqdm
  tk0.close()

def evaluate(dataset, data_loader, model):
  """
  evaluation function to calculate loss on validation
  set for one epoch
  """

  # put model in eval mode
  model.eval()

  # init final_loss to 0
  final_loss=0

  # calculate number of batches and init tqdm
  num_batches = int(len(dataset) / data_loader.batch_size)
  tk0 = tqdm(data_laoder, totall=num_batches)

  # we need no_grad contect of torch. this save memory
  with torch.no_grad():
    for d in tk0:
      inputs = d["image"]
      targets = d["mask"]
      inputs = inputs.to(DEVICE, dtype=torch.float)
      targets = targets.to(DEVICE, dtype=torch.float)
      output = model(inputs)
      loss = criterion(outputs, targets)
      # add loss to final loss
      final_loss += loss
  # close tqdm
  tk0.close()

  # return average loss over all batches
  return final_loss / num_batches

if __name__ == "__main__":
  # read the training csv file
  df = pd.read_csv(TRAINING_CSV)

  # split data into training and validation
  df_train, df_valid = model_selection.train_test_split(
      df, random_state=42, test_size=0.1
  )

  # training and validation images lists/arrays
  training_images = df_train.ImageId.values
  validation_images = df_valid.ImageId.values

  # fetch unet model from segmentation models with specified encoder architecture
  model = smp.Unet(
      encoder_name=ENCODER,
      encoder_weights=ENCODER_WEIGHTS,
      classes=1,
      activation=None,
  )
  
  # segmentation model provides you with a preprocessiong function 
  # that can be used for normalizing images
  # normalization is only applied on images and not masks
  prep_fn = smp.encoders.get_preprocessing_fn(
      ENCODER,
      ENCODER_WEIGHTS
  )

  # send model to device
  model.to(DEVICE)
  # init training dataset
  # transform is True for training data
  train_dataset = SIIMDataset(
      training_images,
      transform=True,
      preprocessing_fn=prep_fn,
  )

  # wrap training dataset in torch's dataloader
  train_loader = torch.utils.data.Dataloader(
      train_dataset,
      batch_size=TRAINING_BATCH_SIZE,
      shuffle=True,
      num_workers=12
  )

  # init validation dataset 
  # augumentation is disabled
  valid_dataset = SIIMDataset(
      validation_images,
      trainsform=False,
      preprocessiong_fn=prep_fn,
  )

  # wrap validation dataset in torch's dataloader
  valid_loader = torch.utils.data.DataLoader(
      valid_dataset,
      batch_size=TEST_BATCH_SIZE,
      shuffle=True,
      num_workers=4
  )

  # we will use Adam optimizer for faster convergence
  optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

  # reduce learning rate when we reach a plateau on loss
  scheduler = lr_scheduler.ReduceLROnPlateau(
      optimizer, mode="min", patience=3, vervose=True
  )

  # wrap model and optimizer with nvidia's apex
  # this is used for mixed precision training
  # if you have a gpu that supports mixesd precision,
  # this is very helpful as it will allow us to fit larger images and larger batches
  model, optimizer = amp.initialize(
      model, optimizer, opt_level="01", verbosity=0
  )

  # if we have more than one gpu, we can use both of them"
  if torch.cuda.device_count() > 1:
    print(f"let's use {torch.cuda.device_count()} gpus!")
    model = nn.DataParallel(model)

  # some logging
  print(f"Training batch size: {TRAINING_BATCH_SIZE}")
  print(f"Test batch size: {TEST_BATCH_SIZE}")
  print(f"Epochs: {EPOCHS}")
  print(f"Image size: {IMAGE_SIZE}")

  # loop over all epochs
  for epoch in range(EPOCHS):
    print(f"Training epoch: {epoch}")
    # train for one epoch
    train(
        train_dataset,
        train_loader,
        model,
        criterion,
        optimizer
    )

    print(f"validation epoch: {epoch}")
    # calculate validation loss
    val_log = evaluate(
        valid_dataset,
        valid_loader,
        model
    )

    # step the scheduler
    scheduler.step(val_log["loss"])
    print("\n")

