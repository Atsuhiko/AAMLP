{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def mean_predictions(probas): \n",
    "    \"\"\" \n",
    "    Create mean predictions \n",
    "    :param probas: 2-d array of probability values \n",
    "    :return: mean probability \n",
    "    \"\"\" \n",
    "    return np.mean(probas, axis=1) \n",
    "\n",
    "def max_voting(preds): \n",
    "    \"\"\" \n",
    "    Create mean predictions \n",
    "    :param probas: 2-d array of prediction values \n",
    "    :return: max voted predictions \n",
    "    \"\"\" \n",
    "    idxs = np.argmax(preds, axis=1) \n",
    "    return np.take_along_axis(preds, idxs[:, None], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_mean(probas): \n",
    "    \"\"\" \n",
    "    Create mean predictions using ranks \n",
    "    :param probas: 2-d array of probability values \n",
    "    :return: mean ranks \n",
    "    \"\"\" \n",
    "    ranked = [] \n",
    "    for i in range(probas.shape[1]): \n",
    "        rank_data = stats.rankdata(probas[:, i]) \n",
    "        ranked.append(rank_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p274 - 275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizeAUC: \n",
    "    \"\"\" \n",
    "    Class for optimizing AUC. \n",
    "    This class is all you need to find best weights for  \n",
    "    any model and for any metric and for any types of predictions. \n",
    "    With very small changes, this class can be used for optimization of  \n",
    "    weights in ensemble models of _any_ type of predictions \n",
    "    \"\"\" \n",
    "    def __init__(self): \n",
    "        self.coef_ = 0 \n",
    " \n",
    "    def _auc(self, coef, X, y): \n",
    "        \"\"\" \n",
    "        This functions calulates and returns AUC. \n",
    "        :param coef: coef list, of the same length as number of models \n",
    "        :param X: predictions, in this case a 2d array \n",
    "        :param y: targets, in our case binary 1d array \n",
    "        \"\"\" \n",
    "        # multiply coefficients with every column of the array \n",
    "        # with predictions. \n",
    "        # this means: element 1 of coef is multiplied by column 1 \n",
    "        # of the prediction array, element 2 of coef is multiplied  \n",
    "        # by column 2 of the prediction array and so on! \n",
    "        x_coef = X * coef \n",
    " \n",
    "        # create predictions by taking row wise sum \n",
    "        predictions = np.sum(x_coef, axis=1) \n",
    "         \n",
    "        # calculate auc score \n",
    "        auc_score = metrics.roc_auc_score(y, predictions) \n",
    " \n",
    "        # return negative auc \n",
    "        return -1.0 * auc_score \n",
    " \n",
    "    def fit(self, X, y): \n",
    "        # remember partial from hyperparameter optimization chapter? \n",
    "        loss_partial = partial(self._auc, X=X, y=y) \n",
    "         \n",
    "        # dirichlet distribution. you can use any distribution you want \n",
    "        # to initialize the coefficients \n",
    "        # we want the coefficients to sum to 1 \n",
    "        initial_coef = np.random.dirichlet(np.ones(X.shape[1]), size=1) \n",
    " \n",
    "        # use scipy fmin to minimize the loss function, in our case auc \n",
    "        # self.coef_ = fmin(loss_partial, initial_coef, disp=True) \n",
    "        trials = Trials()\n",
    "        self.coef_  = fmin(\n",
    "                    fn=loss_partial,\n",
    "                    space=initial_coef,\n",
    "                    algo=tpe.suggest,\n",
    "                    #max_evals=15,\n",
    "                    #trials=trials\n",
    "                    )\n",
    "# 参考：p180  \n",
    "#         hopt = fmin(\n",
    "#         fn=optimization_function,\n",
    "#         space=param_space,\n",
    "#         algo=tpe.suggest,\n",
    "#         max_evals=15,\n",
    "#         trials=trials\n",
    "#         )\n",
    "        # https://qiita.com/nazoking@github/items/f67f92dc60001a43b7dc\n",
    " \n",
    "    def predict(self, X): \n",
    "        # this is similar to _auc function \n",
    "        x_coef = X * self.coef_ \n",
    "        predictions = np.sum(x_coef, axis=1) \n",
    "        return predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p276 - 278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-2: LR AUC = 0.9864756453776521\n",
      "Fold-2: RF AUC = 0.985482682835668\n",
      "Fold-2: XGB AUC = 0.986626525763906\n",
      "Fold-2: Average Pred AUC = 0.9877454086282461\n",
      "Fold-1: LR AUC = 0.9878372488633572\n",
      "Fold-1: RF AUC = 0.9883857302674695\n",
      "Fold-1: XGB AUC = 0.9886868510383386\n",
      "Fold-1: Average prediction AUC = 0.9894718130478413\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-c79671c7571f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptimizeAUC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;31m# dont forget to remove the average column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfold1_preds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myfold1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[0mopt_preds_fold2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfold2_preds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myfold2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_preds_fold2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-2c009f00a359>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     48\u001b[0m                     \u001b[0mfn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_partial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m                     \u001b[0mspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_coef\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m                     \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m                     \u001b[1;31m#max_evals=15,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                     \u001b[1;31m#trials=trials\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Python37-gpu\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    532\u001b[0m             \u001b[0mtrials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_trials_to_calculate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints_to_evaluate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m     \u001b[0mdomain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDomain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m     rval = FMinIter(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Python37-gpu\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fn, expr, workdir, pass_expr_memo_ctrl, name, loss_target)\u001b[0m\n\u001b[0;32m    850\u001b[0m         \u001b[0mbefore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdfs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    851\u001b[0m         \u001b[1;31m# -- raises exception if expr contains cycles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 852\u001b[1;33m         \u001b[0mpyll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoposort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    853\u001b[0m         \u001b[0mvh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVectorizeHelper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms_new_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m         \u001b[1;31m# -- raises exception if v_expr contains cycles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Python37-gpu\\lib\\site-packages\\hyperopt\\pyll\\base.py\u001b[0m in \u001b[0;36mtoposort\u001b[1;34m(expr)\u001b[0m\n\u001b[0;32m    710\u001b[0m         \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_edges_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn_in\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopological_sort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 712\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mexpr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    713\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb \n",
    "from sklearn.datasets import make_classification \n",
    "from sklearn import ensemble \n",
    "from sklearn import linear_model \n",
    "from sklearn import metrics \n",
    "from sklearn import model_selection\n",
    "from functools import partial # need to be installed --> Hyperparameter optimization\n",
    "from hyperopt import hp, fmin, tpe, Trials # conda install -c conda-forge hyperopt --> Hyperparameter optimization\n",
    "\n",
    "# make a binary classification dataset with 10k samples \n",
    "# and 25 features \n",
    "X, y = make_classification(n_samples=10000, n_features=25) \n",
    " \n",
    "# split into two folds (for this example) \n",
    "xfold1, xfold2, yfold1, yfold2 = model_selection.train_test_split( \n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.5, \n",
    "    stratify=y \n",
    ") \n",
    " \n",
    "# fit models on fold 1 and make predictions on fold 2 \n",
    "# we have 3 models: \n",
    "# logistic regression, random forest and xgboost \n",
    "logreg = linear_model.LogisticRegression() \n",
    "rf = ensemble.RandomForestClassifier() \n",
    "xgbc = xgb.XGBClassifier() \n",
    " \n",
    "# fit all models on fold 1 data \n",
    "logreg.fit(xfold1, yfold1) \n",
    "rf.fit(xfold1, yfold1) \n",
    "xgbc.fit(xfold1, yfold1) \n",
    " \n",
    "# predict all models on fold 2 \n",
    "# take probability for class 1 \n",
    "pred_logreg = logreg.predict_proba(xfold2)[:, 1] \n",
    "pred_rf = rf.predict_proba(xfold2)[:, 1] \n",
    "pred_xgbc = xgbc.predict_proba(xfold2)[:, 1] \n",
    "\n",
    "# create an average of all predictions \n",
    "# that is the simplest ensemble \n",
    "avg_pred = (pred_logreg + pred_rf + pred_xgbc) / 3 \n",
    " \n",
    "# a 2d array of all predictions \n",
    "fold2_preds = np.column_stack(( \n",
    "    pred_logreg, \n",
    "    pred_rf, \n",
    "    pred_xgbc, \n",
    "    avg_pred \n",
    ")) \n",
    " \n",
    "# calculate and store individual AUC values \n",
    "aucs_fold2 = [] \n",
    "for i in range(fold2_preds.shape[1]): \n",
    "    auc = metrics.roc_auc_score(yfold2, fold2_preds[:, i]) \n",
    "    aucs_fold2.append(auc) \n",
    "    \n",
    "print(f\"Fold-2: LR AUC = {aucs_fold2[0]}\") \n",
    "print(f\"Fold-2: RF AUC = {aucs_fold2[1]}\") \n",
    "print(f\"Fold-2: XGB AUC = {aucs_fold2[2]}\") \n",
    "print(f\"Fold-2: Average Pred AUC = {aucs_fold2[3]}\") \n",
    " \n",
    "# now we repeat the same for the other fold \n",
    "# this is not the ideal way, if you ever have to repeat code,  \n",
    "# create a function! \n",
    "# fit models on fold 2 and make predictions on fold 1 \n",
    "logreg = linear_model.LogisticRegression() \n",
    "rf = ensemble.RandomForestClassifier() \n",
    "xgbc = xgb.XGBClassifier() \n",
    " \n",
    "logreg.fit(xfold2, yfold2) \n",
    "rf.fit(xfold2, yfold2) \n",
    "xgbc.fit(xfold2, yfold2) \n",
    " \n",
    "pred_logreg = logreg.predict_proba(xfold1)[:, 1] \n",
    "pred_rf = rf.predict_proba(xfold1)[:, 1] \n",
    "pred_xgbc = xgbc.predict_proba(xfold1)[:, 1] \n",
    "avg_pred = (pred_logreg + pred_rf + pred_xgbc) / 3 \n",
    " \n",
    "fold1_preds = np.column_stack(( \n",
    "    pred_logreg, \n",
    "    pred_rf, \n",
    "    pred_xgbc, \n",
    "    avg_pred \n",
    ")) \n",
    "\n",
    "aucs_fold1 = [] \n",
    "for i in range(fold1_preds.shape[1]): \n",
    "    auc = metrics.roc_auc_score(yfold1, fold1_preds[:, i]) \n",
    "    aucs_fold1.append(auc) \n",
    "\n",
    "print(f\"Fold-1: LR AUC = {aucs_fold1[0]}\") \n",
    "print(f\"Fold-1: RF AUC = {aucs_fold1[1]}\") \n",
    "print(f\"Fold-1: XGB AUC = {aucs_fold1[2]}\") \n",
    "print(f\"Fold-1: Average prediction AUC = {aucs_fold1[3]}\") \n",
    " \n",
    "# find optimal weights using the optimizer \n",
    "opt = OptimizeAUC() \n",
    "# dont forget to remove the average column \n",
    "opt.fit(fold1_preds[:, :-1], yfold1) \n",
    "opt_preds_fold2 = opt.predict(fold2_preds[:, :-1]) \n",
    "auc = metrics.roc_auc_score(yfold2, opt_preds_fold2) \n",
    "print(f\"Optimized AUC, Fold 2 = {auc}\") \n",
    "print(f\"Coefficients = {opt.coef_}\") \n",
    " \n",
    "opt = OptimizeAUC() \n",
    "opt.fit(fold2_preds[:, :-1], yfold2) \n",
    "opt_preds_fold1 = opt.predict(fold1_preds[:, :-1]) \n",
    "auc = metrics.roc_auc_score(yfold1, opt_preds_fold1) \n",
    "print(f\"Optimized AUC, Fold 1 = {auc}\") \n",
    "print(f\"Coefficients = {opt.coef_}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold-2: LR AUC = 0.9145446769443348   \n",
    "Fold-2: RF AUC = 0.9269918948683287   \n",
    "Fold-2: XGB AUC = 0.9302436595508696   \n",
    "Fold-2: Average Pred AUC = 0.927701495890154   \n",
    " \n",
    "Fold-1: LR AUC = 0.9050872233256017   \n",
    "Fold-1: RF AUC = 0.9179382818311258   \n",
    "Fold-1: XGB AUC = 0.9195837242005629   \n",
    "Fold-1: Average prediction AUC = 0.9189669233123695   \n",
    " \n",
    "Optimization terminated successfully.   \n",
    "         Current function value: -0.920643   \n",
    "         Iterations: 50   \n",
    "         Function evaluations: 109   \n",
    "Optimized AUC, Fold 2 = 0.9305386199756128   \n",
    "Coefficients = [-0.00188194  0.19328336  0.35891836]   \n",
    "\n",
    "Optimization terminated successfully.   \n",
    "         Current function value: -0.931232   \n",
    "         Iterations: 56   \n",
    "         Function evaluations: 113   \n",
    "Optimized AUC, Fold 1 = 0.9192523637234037   \n",
    "Coefficients = [-0.15655124  0.22393151  0.58711366]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
